{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad3674c",
   "metadata": {},
   "source": [
    "# Deliverable 3: Data Preprocessing Pipeline + Baseline ML Models\n",
    "\n",
    "## AI-Powered Resume Screening System - Machine Learning\n",
    "\n",
    "**Goal:** Build a complete data preprocessing pipeline and train baseline ML models to classify resumes into job categories.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. Load Dataset\n",
    "2. Data Exploration & Cleaning\n",
    "3. Feature Engineering (TF-IDF + Structured Features)\n",
    "4. Train-Test Split\n",
    "5. Baseline Model 1: Random Forest\n",
    "6. Baseline Model 2: Logistic Regression\n",
    "7. Model Comparison & Evaluation\n",
    "8. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, classification_report, confusion_matrix)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ac600",
   "metadata": {},
   "source": [
    "## Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a02cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset using kagglehub\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"snehaanbhawal/resume-dataset\")\n",
    "print(f\"Dataset path: {path}\")\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(path + '/Resume/Resume.csv')\n",
    "\n",
    "print(f\"\\nüìä Dataset Information:\")\n",
    "print(f\"Total resumes: {len(df)}\")\n",
    "print(f\"Number of job categories: {df['Category'].nunique()}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3242e13",
   "metadata": {},
   "source": [
    "## Step 2: Data Exploration & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Display category distribution\n",
    "print(\"\\nüìã Job Category Distribution:\")\n",
    "print(df['Category'].value_counts())\n",
    "\n",
    "# Visualize category distribution\n",
    "plt.figure(figsize=(14, 6))\n",
    "df['Category'].value_counts().plot(kind='bar', color='steelblue')\n",
    "plt.title('Distribution of Job Categories', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Job Category')\n",
    "plt.ylabel('Number of Resumes')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809db72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "def clean_resume_text(text):\n",
    "    \"\"\"\n",
    "    Clean resume text by:\n",
    "    1. Removing URLs\n",
    "    2. Removing special characters\n",
    "    3. Converting to lowercase\n",
    "    4. Removing extra whitespace\n",
    "    \"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove special characters but keep letters, numbers, and spaces\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "print(\"üßπ Cleaning resume text...\")\n",
    "df['Resume_cleaned'] = df['Resume_str'].apply(clean_resume_text)\n",
    "\n",
    "# Display example\n",
    "print(\"\\nüìÑ Original Resume (first 200 chars):\")\n",
    "print(df['Resume_str'].iloc[0][:200])\n",
    "print(\"\\nüìÑ Cleaned Resume (first 200 chars):\")\n",
    "print(df['Resume_cleaned'].iloc[0][:200])\n",
    "\n",
    "print(\"\\n‚úÖ Text cleaning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8342144f",
   "metadata": {},
   "source": [
    "## Step 3: Feature Engineering\n",
    "\n",
    "We'll create two types of features:\n",
    "1. **TF-IDF Features**: Capture important words in resumes\n",
    "2. **Structured Features**: Skills count, resume length, word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe67b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. TF-IDF Features (Text Vectorization)\n",
    "print(\"üî§ Creating TF-IDF features...\")\n",
    "\n",
    "# TF-IDF converts text into numerical features\n",
    "# max_features=300 means we keep the 300 most important words\n",
    "# ngram_range=(1,2) means we consider both single words and pairs of words\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=300, \n",
    "    stop_words='english',  # Remove common words like 'the', 'is', etc.\n",
    "    ngram_range=(1, 2)     # Use unigrams and bigrams\n",
    ")\n",
    "\n",
    "# Fit and transform the cleaned resume text\n",
    "tfidf_features = vectorizer.fit_transform(df['Processed_Text'])\n",
    "\n",
    "print(f\"‚úÖ TF-IDF features created: {tfidf_features.shape}\")\n",
    "print(f\"   Number of resumes: {tfidf_features.shape[0]}\")\n",
    "print(f\"   Number of TF-IDF features: {tfidf_features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef94dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Structured Features\n",
    "print(\"\\nüîß Creating structured features...\")\n",
    "\n",
    "# Count skills in each resume\n",
    "def count_skills(text):\n",
    "    \"\"\"Count how many technical skills appear in the resume\"\"\"\n",
    "    skills = ['python', 'java', 'sql', 'javascript', 'machine learning', \n",
    "              'aws', 'docker', 'react', 'nodejs', 'git', 'excel', \n",
    "              'data analysis', 'leadership', 'management']\n",
    "    count = sum(1 for skill in skills if skill in text.lower())\n",
    "    return count\n",
    "\n",
    "# Create structured features\n",
    "df['num_skills'] = df['Resume_str'].apply(count_skills)\n",
    "df['resume_length'] = df['Resume_cleaned'].apply(len)\n",
    "df['word_count'] = df['Resume_cleaned'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(\"‚úÖ Structured features created:\")\n",
    "print(f\"   - num_skills: Count of technical skills\")\n",
    "print(f\"   - resume_length: Character count\")\n",
    "print(f\"   - word_count: Number of words\")\n",
    "\n",
    "# Display examples\n",
    "print(\"\\nüìä Feature Examples:\")\n",
    "print(df[['num_skills', 'resume_length', 'word_count']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa6ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Combine all features\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "print(\"\\nüîó Combining features...\")\n",
    "\n",
    "# Get structured features as numpy array\n",
    "structured_features = df[['num_skills', 'resume_length', 'word_count']].values\n",
    "\n",
    "# Combine TF-IDF features (sparse matrix) with structured features (dense array)\n",
    "X = hstack([tfidf_features, structured_features])\n",
    "\n",
    "print(f\"‚úÖ Final feature matrix shape: {X.shape}\")\n",
    "print(f\"   Total features: {X.shape[1]} (300 TF-IDF + 3 structured)\")\n",
    "\n",
    "# Prepare labels (job categories)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Category'])\n",
    "\n",
    "print(f\"\\nüìã Labels prepared:\")\n",
    "print(f\"   Number of classes: {len(label_encoder.classes_)}\")\n",
    "print(f\"   Classes: {label_encoder.classes_[:5]}... (showing first 5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c1b62",
   "metadata": {},
   "source": [
    "## Step 4: Train-Test Split\n",
    "\n",
    "Split data into training (80%) and testing (20%) sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbfb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 80% training, 20% testing\n",
    "# stratify=y ensures each class is proportionally represented in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42,    # For reproducibility\n",
    "    stratify=y          # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(\"üìä Data Split:\")\n",
    "print(f\"Training samples: {X_train.shape[0]} ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Testing samples:  {X_test.shape[0]} ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Features per sample: {X_train.shape[1]}\")\n",
    "print(\"\\n‚úÖ Ready to train models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb2c357",
   "metadata": {},
   "source": [
    "## Step 5: Baseline Model 1 - Random Forest Classifier\n",
    "\n",
    "Random Forest is an ensemble learning method that combines multiple decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5bb35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"üå≤ Training Random Forest Classifier...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Create Random Forest model\n",
    "# n_estimators=100 means we use 100 decision trees\n",
    "# max_depth=20 limits tree depth to prevent overfitting\n",
    "# random_state=42 ensures reproducibility\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all CPU cores for faster training\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚úÖ Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Make predictions on test set\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_precision = precision_score(y_test, rf_predictions, average='weighted', zero_division=0)\n",
    "rf_recall = recall_score(y_test, rf_predictions, average='weighted')\n",
    "rf_f1 = f1_score(y_test, rf_predictions, average='weighted')\n",
    "\n",
    "print(\"\\nüìä Random Forest Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy:  {rf_accuracy:.4f} ({rf_accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {rf_precision:.4f}\")\n",
    "print(f\"Recall:    {rf_recall:.4f}\")\n",
    "print(f\"F1-Score:  {rf_f1:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b36cf5",
   "metadata": {},
   "source": [
    "## Step 6: Baseline Model 2 - Logistic Regression\n",
    "\n",
    "Logistic Regression is a linear model for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd5658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìà Training Logistic Regression Classifier...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Create Logistic Regression model\n",
    "# max_iter=1000 allows enough iterations for convergence\n",
    "# multi_class='auto' handles multiple job categories\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚úÖ Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Make predictions on test set\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "lr_precision = precision_score(y_test, lr_predictions, average='weighted', zero_division=0)\n",
    "lr_recall = recall_score(y_test, lr_predictions, average='weighted')\n",
    "lr_f1 = f1_score(y_test, lr_predictions, average='weighted')\n",
    "\n",
    "print(\"\\nüìä Logistic Regression Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy:  {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {lr_precision:.4f}\")\n",
    "print(f\"Recall:    {lr_recall:.4f}\")\n",
    "print(f\"F1-Score:  {lr_f1:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9accce",
   "metadata": {},
   "source": [
    "## Step 7: Model Comparison & Evaluation\n",
    "\n",
    "Let's compare both models side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Logistic Regression'],\n",
    "    'Accuracy': [rf_accuracy, lr_accuracy],\n",
    "    'Precision': [rf_precision, lr_precision],\n",
    "    'Recall': [rf_recall, lr_recall],\n",
    "    'F1-Score': [rf_f1, lr_f1]\n",
    "})\n",
    "\n",
    "print(\"\\nüìä MODEL COMPARISON TABLE\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Determine best model\n",
    "best_model_name = 'Random Forest' if rf_f1 > lr_f1 else 'Logistic Regression'\n",
    "best_f1 = max(rf_f1, lr_f1)\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   F1-Score: {best_f1:.4f}\")\n",
    "\n",
    "# Bar chart comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: All metrics comparison\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "rf_scores = [rf_accuracy, rf_precision, rf_recall, rf_f1]\n",
    "lr_scores = [lr_accuracy, lr_precision, lr_recall, lr_f1]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, rf_scores, width, label='Random Forest', color='steelblue')\n",
    "axes[0].bar(x + width/2, lr_scores, width, label='Logistic Regression', color='coral')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Model Performance Comparison')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: F1-Score comparison\n",
    "models = ['Random Forest', 'Logistic Regression']\n",
    "f1_scores = [rf_f1, lr_f1]\n",
    "colors = ['steelblue', 'coral']\n",
    "\n",
    "axes[1].bar(models, f1_scores, color=colors)\n",
    "axes[1].set_ylabel('F1-Score')\n",
    "axes[1].set_title('F1-Score Comparison (Higher is Better)')\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(f1_scores):\n",
    "    axes[1].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfec91d",
   "metadata": {},
   "source": [
    "## Step 8: Detailed Classification Report & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report for Random Forest (Best Model)\n",
    "print(\"üìã DETAILED CLASSIFICATION REPORT - RANDOM FOREST\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test, rf_predictions, target_names=label_encoder.classes_))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ebb904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for Random Forest\n",
    "cm = confusion_matrix(y_test, rf_predictions)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_encoder.classes_, \n",
    "            yticklabels=label_encoder.classes_,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Random Forest Classifier', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Confusion Matrix Interpretation:\")\n",
    "print(\"   - Diagonal values (dark blue) = Correct predictions\")\n",
    "print(\"   - Off-diagonal values = Misclassifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f055be97",
   "metadata": {},
   "source": [
    "## Step 9: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest\n",
    "feature_names = vectorizer.get_feature_names_out().tolist() + ['num_skills', 'resume_length', 'word_count']\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Get top 15 most important features\n",
    "top_indices = np.argsort(importances)[-15:]\n",
    "top_features = [feature_names[i] for i in top_indices]\n",
    "top_importances = importances[top_indices]\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(15), top_importances, color='steelblue')\n",
    "plt.yticks(range(15), top_features)\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Top 15 Most Important Features - Random Forest', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîë Top 5 Most Important Features:\")\n",
    "for i, (feature, importance) in enumerate(zip(top_features[-5:], top_importances[-5:]), 1):\n",
    "    print(f\"   {i}. {feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4125a7a",
   "metadata": {},
   "source": [
    "## Step 10: Save Models for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772754b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create directory for models if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "joblib.dump(rf_model, 'models/random_forest_model.pkl')\n",
    "joblib.dump(lr_model, 'models/logistic_regression_model.pkl')\n",
    "joblib.dump(vectorizer, 'models/tfidf_vectorizer.pkl')\n",
    "joblib.dump(label_encoder, 'models/label_encoder.pkl')\n",
    "\n",
    "print(\"üíæ Models saved successfully!\")\n",
    "print(\"   ‚úÖ models/random_forest_model.pkl\")\n",
    "print(\"   ‚úÖ models/logistic_regression_model.pkl\")\n",
    "print(\"   ‚úÖ models/tfidf_vectorizer.pkl\")\n",
    "print(\"   ‚úÖ models/label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a38218f",
   "metadata": {},
   "source": [
    "## Summary & Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fd54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üéâ DELIVERABLE 3 COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä SUMMARY:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Dataset Size: {len(df)} resumes\")\n",
    "print(f\"Number of Job Categories: {len(label_encoder.classes_)}\")\n",
    "print(f\"Training Samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing Samples: {X_test.shape[0]}\")\n",
    "print(f\"Total Features: {X.shape[1]} (300 TF-IDF + 3 structured)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nü§ñ MODELS TRAINED:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"1. Random Forest Classifier\")\n",
    "print(f\"   - Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"   - F1-Score: {rf_f1:.4f}\")\n",
    "print()\n",
    "print(\"2. Logistic Regression\")\n",
    "print(f\"   - Accuracy: {lr_accuracy:.4f}\")\n",
    "print(f\"   - F1-Score: {lr_f1:.4f}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   F1-Score: {best_f1:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ All components successfully implemented:\")\n",
    "print(\"   ‚úì Data preprocessing pipeline\")\n",
    "print(\"   ‚úì Feature engineering (TF-IDF + structured features)\")\n",
    "print(\"   ‚úì Two baseline ML models trained\")\n",
    "print(\"   ‚úì Performance metrics calculated\")\n",
    "print(\"   ‚úì Visualizations created\")\n",
    "print(\"   ‚úì Models saved for future use\")\n",
    "\n",
    "print(\"\\nüìà Next Steps (Deliverable 4):\")\n",
    "print(\"   ‚Üí Integrate BERT for semantic matching\")\n",
    "print(\"   ‚Üí Implement Reinforcement Learning agent\")\n",
    "print(\"   ‚Üí Add SHAP/LIME explainability\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c0518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3.9.6",
   "language": "python",
   "name": "python_3.9.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
